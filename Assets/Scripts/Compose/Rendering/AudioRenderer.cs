// <auto-generated> to shut up linter for now
// using System.Collections.Generic;
// using ArcCreate.Gameplay.Data;
// using UnityEngine;

// namespace ArcCreate.Compose.Rendering
// {
//     public class AudioRenderer
//     {
//         private const string V = "Writing to ";

//         public void CreateAudio()
//         {
//             // Get list of notes
//             List<Note> tapSound = new List<Note>();
//             List<Note> arcSound = new List<Note>();
//             Dictionary<string, List<Note>> sfxSound = new Dictionary<string, List<Note>>();
//             sfxAudio = ArcEffectManager.Instance.SfxAudios;

//             int offset = Services.Gameplay.Audio.FullOffset;
//             int startRange = start - offset;
//             int endRange = end - offset;

//             tapSound.AddRange(ArcTapNoteManager.Instance.Taps.Where((n) => n.Timing >= startRange && n.Timing <= endRange && !n.NoInput));
//             tapSound.AddRange(ArcHoldNoteManager.Instance.Holds.Where((n) => n.Timing >= startRange && n.Timing <= endRange && !n.NoInput));
//             IEnumerable<ArcArc> arcs = ArcArcManager.Instance.Arcs.Where((n) => n.Timing >= startRange && n.Timing <= endRange && !n.NoInput);
//             arcSound.AddRange(arcs.Where((n) => !n.IsVoid && n.Timing != n.EndTiming));

//             foreach (Arc a in ArcArcManager.Instance.Arcs)
//             {
//                 arcSound.AddRange(a.ArcTaps.Where((n) => n.Timing >= startRange && n.Timing <= endRange && n.Arc.Effect == "none"));
//             }

//             foreach (Arc a in arcs)
//             {
//                 if (a.Effect == "none")
//                 {
//                     continue;
//                 }

//                 a.ArcTaps.ForEach((n) =>
//                 {
//                     if (sfxSound.ContainsKey(n.Arc.Effect))
//                         sfxSound[n.Arc.Effect].Add(n);
//                     else
//                     {
//                         sfxSound.Add(n.Arc.Effect, new List<ArcNote>());
//                         sfxSound[n.Arc.Effect].Add(n);
//                     }
//                 });
//             }

//             Debug.Log("Creating tapsound audio for " + (tapSound.Count + arcSound.Count + sfxSound.Count) + " notes.");

//             //...
//             int channels = tapAudio.channels;
//             int frequency = tapAudio.frequency;
//             if (arcAudio.channels != channels || shutterCloseAudio.channels != channels || shutterOpenAudio.channels != channels
//             || arcAudio.frequency != frequency || shutterCloseAudio.frequency != frequency || shutterOpenAudio.frequency != frequency)
//                 throw new Exception("Internal audio error: Internal sfx wav have differing frequency and channels count");

//             //Get raw byte array from audio clips
//             float[] tap = GetSamples(tapAudio);
//             float[] arc = GetSamples(arcAudio);
//             Dictionary<string, float[]> sfx = new Dictionary<string, float[]>();
//             foreach (KeyValuePair<string, AudioClip> sa in sfxAudio)
//             {
//                 sfx.Add(sa.Key, GetSamples(sa.Value));
//             }
//             float[] shutterClose = GetSamples(shutterCloseAudio);
//             float[] shutterOpen = GetSamples(shutterOpenAudio);
//             float effectVolume = AdeSoundDialog.Instance.EffectSource.volume;
//             if (!ArcGameplayManager.Instance.Auto) effectVolume = 0;

//             //Combine
//             float audioLength = (end - start) / 1000f;
//             if (start <= 0) audioLength += AdeShutterManager.FullSequence;
//             float[] samples = new float[(int)(audioLength * frequency) * channels];
//             Debug.Log("Prepared samples array of size " + samples.Length);

//             Dictionary<string, float[]> sfxSamples = new Dictionary<string, float[]>();
//             foreach (KeyValuePair<string, AudioClip> s in sfxAudio)
//             {
//                 AudioClip clip = s.Value;
//                 if (clip.channels != channels || clip.frequency != frequency)
//                     throw new Exception(string.Format(I.S["incompatiblesfx"], s.Key, channels, frequency));

//                 sfxSamples.Add(s.Key, new float[(int)(audioLength * s.Value.frequency) * s.Value.channels]);
//                 Debug.Log($"Prepared {s.Key} sfx samples array of size: {sfxSamples[s.Key].Length}");
//             }

//             if (start <= 0)
//             {
//                 for (int i = 0; i < shutterClose.Length; i++)
//                 {
//                     samples[i] = shutterClose[i];
//                 }

//                 int shutterOpenOffset = (int)((AdeShutterManager.Duration + AdeShutterManager.WaitBetween) * frequency) * channels;
//                 for (int i = 0; i < shutterOpen.Length; i++)
//                 {
//                     samples[i + shutterOpenOffset] = shutterOpen[i];
//                 }
//             }

//             foreach (ArcNote n in tapSound)
//             {
//                 int start = TimingToSampleIndex(n.Timing, channels, frequency);
//                 for (int i = 0; i < tap.Length; i++)
//                     if (start + i < samples.Length)
//                         samples[start + i] += tap[i] * effectVolume;
//             }
//             foreach (ArcNote n in arcSound)
//             {
//                 int start = TimingToSampleIndex(n.Timing, channels, frequency);
//                 for (int i = 0; i < arc.Length; i++)
//                     if (start + i < samples.Length)
//                         samples[start + i] += arc[i] * effectVolume;
//             }
//             foreach (KeyValuePair<string, List<ArcNote>> sound in sfxSound)
//             {
//                 foreach (ArcNote n in sound.Value)
//                 {
//                     int start = TimingToSampleIndex(n.Timing, sfxAudio[sound.Key].channels, sfxAudio[sound.Key].frequency);
//                     for (int i = 0; i < sfx[sound.Key].Length; i++)
//                         if (start + i < sfxSamples[sound.Key].Length)
//                             sfxSamples[sound.Key][start + i] += sfx[sound.Key][i];
//                 }
//             }

//             /* Normal Note */
//             byte[] byteData = new byte[samples.Length * 2];
//             Debug.Log("Converting to raw bytes");

//             for (int i = 0; i < samples.Length; i++)
//             {
//                 int intData = (short)(samples[i] * Int16.MaxValue);
//                 byte[] sample = BitConverter.GetBytes(intData);
//                 byteData[i * 2] = sample[0];
//                 byteData[i * 2 + 1] = sample[1];
//             }

//             //Write the sfx wav file
//             Debug.Log(V + GetPath("sfx.wav"));
//             MemoryStream memoryStream = new MemoryStream(byteData);
//             WaveFormat format = new WaveFormat(frequency, 16, channels);
//             IWaveProvider wave = new RawSourceWaveStream(memoryStream, format);
//             WaveFileWriter.CreateWaveFile(GetPath("sfx.wav"), wave);

//             /* Sfx Sky Note */
//             foreach (KeyValuePair<string, float[]> sfxsample in sfxSamples)
//             {
//                 byteData = new byte[sfxsample.Value.Length * 2];
//                 Debug.Log($"Converting to raw bytes (sfx: {sfxsample.Key})");

//                 for (int i = 0; i < sfxsample.Value.Length; i++)
//                 {
//                     int intData = (short)(sfxsample.Value[i] * Int16.MaxValue);
//                     byte[] sample = BitConverter.GetBytes(intData);
//                     byteData[i * 2] = sample[0];
//                     byteData[i * 2 + 1] = sample[1];
//                 }

//                 // Write the sfx wav file
//                 Debug.Log("Writing to " + GetPath($"sfx_{sfxsample.Key}.wav"));
//                 memoryStream = new MemoryStream(byteData);
//                 format = new WaveFormat(sfxAudio[sfxsample.Key].frequency, 16, sfxAudio[sfxsample.Key].channels);
//                 wave = new RawSourceWaveStream(memoryStream, format);
//                 WaveFileWriter.CreateWaveFile(GetPath($"sfx_{sfxsample.Key}.wav"), wave);
//             }

//             // Get song data
//             Debug.Log("Cutting track from " + start + " to " + end);
//             AudioClip songAudio = ArcAudioManager.Instance.Clip;
//             float[] songSamples = GetSongSamples(songAudio);
//             byte[] songBytes = new byte[songSamples.Length * 2];
//             float songVolume = AdeSoundDialog.Instance.ChartSource.volume;

//             Debug.Log("Converting to raw bytes");
//             for (int i = 0; i < songSamples.Length; i++)
//             {
//                 int intData = (short)(songSamples[i] * songVolume * Int16.MaxValue);
//                 byte[] sample = BitConverter.GetBytes(intData);
//                 songBytes[i * 2] = sample[0];
//                 songBytes[i * 2 + 1] = sample[1];
//             }

//             //Write song file
//             Debug.Log("Writing to " + GetPath("song.wav"));
//             memoryStream = new MemoryStream(songBytes);
//             format = new WaveFormat(songAudio.frequency, 16, songAudio.channels);
//             wave = new RawSourceWaveStream(memoryStream, format);
//             WaveFileWriter.CreateWaveFile(GetPath("song.wav"), wave);
//         }

//         private int TimingToSampleIndex(int timing, int channels, int frequency)
//         {
//             int offset = ArcAudioManager.Instance.AudioOffset;
//             if (start <= 0) offset += (int)(AdeShutterManager.FullSequence * 1000);

//             int samples = (int)((timing - start + offset) / 1000f * frequency);
//             return samples * channels;
//         }


//         private float[] GetSamples(AudioClip clip)
//         {
//             float[] samples = new float[clip.samples * clip.channels];
//             clip.GetData(samples, 0);
//             return samples;
//         }


//         private float[] GetSongSamples(AudioClip clip)
//         {
//             float audioLength = (end - start) / 1000f;
//             if (start <= 0) audioLength += AdeShutterManager.FullSequence;
//             float[] samples = new float[(int)(audioLength * clip.frequency) * clip.channels];

//             int readOffset = (int)((start / 1000f) * clip.frequency);

//             clip.GetData(samples, readOffset);

//             // shift forward
//             if (start <= 0)
//             {
//                 int shiftIndex = (int)(AdeShutterManager.FullSequence * clip.frequency) * clip.channels;
//                 for (int i = samples.Length - 1; i >= shiftIndex; i--)
//                 {
//                     samples[i] = samples[i - shiftIndex];
//                 }
//                 for (int i = 0; i < shiftIndex; i++)
//                 {
//                     samples[i] = 0;
//                 }
//             }
//             return samples;
//         }
//     }
// }